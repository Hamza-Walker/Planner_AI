apiVersion: apps/v1
kind: Deployment
metadata:
  name: planner-ai-backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: planner-ai-backend
  template:
    metadata:
      labels:
        app: planner-ai-backend
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
    spec:
      # Tolerations for energy-aware rescheduling
      # This allows the pod to run on nodes with energy-role taints
      tolerations:
        - key: "energy-role"
          operator: "Exists"
          effect: "NoExecute"
      containers:
        - name: backend
          image: planner-ai-backend:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 8000
          env:
            - name: ENVIRONMENT
              value: "development"
            # PostgreSQL Durable Queue Configuration
            - name: USE_DURABLE_QUEUE
              value: "true"
            - name: DATABASE_URL
              value: "postgresql://planner:planner_secret_2026@postgres:5432/planner_ai"
            - name: STALE_RECOVERY_INTERVAL_S
              value: "60"
            # Optional: enable energy-aware behavior using the exercise 10 price simulator
            - name: ENERGY_STATUS_URL
              value: "http://price-simulator:8000"
            - name: ENERGY_PRICE_THRESHOLD_EUR
              value: "0.70"
            - name: ENERGY_FAIL_OPEN
              value: "true"
            - name: QUEUE_POLL_INTERVAL_S
              value: "1"
            # Electricity Maps API Key (Optional)
            - name: ELECTRICITY_MAPS_API_KEY
              value: "6BANkzBnWcNDkA7lrT3n"
            # CodeCarbon push gateway URL
            - name: PROMETHEUS_PUSH_URL
              value: "http://pushgateway:9091"
            # LLM Configuration
            - name: LLM_PROVIDER
              value: "ollama"
            - name: OLLAMA_BASE_URL
              value: "http://host.minikube.internal:11434"
            - name: OLLAMA_MODEL
              value: "llama3.2"
            - name: LLM_MODEL_LARGE
              value: "qwen:14b"
            - name: LLM_MODEL_SMALL
              value: "llama3.2"
